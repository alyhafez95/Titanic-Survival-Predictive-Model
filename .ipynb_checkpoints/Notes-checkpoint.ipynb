{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "### linear algebra\n",
    "import numpy as np\n",
    "import math  \n",
    "### data processing\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "### data visualization\n",
    "import seaborn as sns \n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "### algorithms \n",
    "from sklearn import linear_model <br>\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code scraps\n",
    "### descriptive\n",
    "train_df.head() \n",
    "train_df.shape \n",
    "train_df.columns \n",
    "train_df.dtypes \n",
    "train_df.info() \n",
    "train_df.Embarked.value_counts() \n",
    "train_df.Cabin.value_counts() \n",
    "train_df.isnull().any().sum()\n",
    "list(string.ascii_uppercase[0:9])  \n",
    "pd.value_counts(train_df.Sex)  \n",
    "\n",
    "### clean\n",
    "train_df.drop(columns='Name')\n",
    "train_df.dropna(inplace = True\n",
    "### encode one column at a time\n",
    "Sex_dummies = pd.get_dummies(train_df.Sex, prefix='Sex').iloc[:,1:] \n",
    "Embarked_dummies=pd.get_dummies(train_df.Embarked, prefix='Embarked').iloc[:,1:] \n",
    "pd.concat([train_df,Embarked_dummies,Sex_dummies],axis=1) \n",
    "Encoded_file.to_csv('Encoded_file.csv')\n",
    "### dummy encode specific column(s)(with k number of value_counts) -> produces K-1 columns with values=1,0\n",
    "encoded_file = pd.get_dummies(train_df, columns=['Pclss', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked'], drop_first=True) \n",
    "### save encoded data to csv\n",
    "encoded_file.to_csv('encoded_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read .jmp file with Python Pandas into Pandas dataframe\n",
    "\n",
    "import pandas as pd  \n",
    "from win32com.client import Dispatch  \n",
    "\n",
    "jmp = Dispatch(\"JMP.Application\")  \n",
    "doc = jmp.OpenDocument('sasjmpfile.jmp')  \n",
    "doc.SaveAs('sasjmpfile.csv')  \n",
    "\n",
    "df = pd.read_csv('sasjmpfile.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace less common names to more common ones\n",
    "\n",
    "\n",
    "train_df.replace(['Capt', 'Col', 'Don', 'Jonkheer', 'Lady', \n",
    "                        'Major', 'Mlle', 'Mme', 'Ms', 'Sir', 'th', 'Dona'], \n",
    "                       ['Mr', 'Mr', 'Mr', 'Mr', 'Mrs',\n",
    "                        'Mr', 'Miss', 'Mrs', 'Miss', 'Mr', 'Miss', 'Mrs'], inplace= True)\n",
    "\n",
    "\n",
    "test_df.replace(['Capt', 'Col', 'Don', 'Jonkheer', 'Lady', \n",
    "                        'Major', 'Mlle', 'Mme', 'Ms', 'Sir', 'th', 'Dona'], \n",
    "                       ['Mr', 'Mr', 'Mr', 'Mr', 'Mrs',\n",
    "                        'Mr', 'Miss', 'Mrs', 'Miss', 'Mr', 'Miss', 'Mrs'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split columns\n",
    "new = train_df[\"Name\"].str.split(\" \", n = 3, expand = True) \n",
    "train_df[\"Last Name\"]= new[0] \n",
    "train_df[\"Suffix \"]= new[1]\n",
    "train_df[\"First Name\"]= new[2]\n",
    "train_df.drop_df(columns =[\"Name\", \"3\"], inplace = True) \n",
    "train_df.iloc[:,3]  Read Column \"3\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visuals\n",
    "train_df.plot(subplots=True, figsize=(18,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### missing data calculator\n",
    "null_total = train_df.isnull().sum() <br> <br>\n",
    "null_percent = train_df.isnull().sum()/train_df.isnull().count()*100 <br>\n",
    "null_percent_r = (round(percent_1, 1)).sort_values(ascending= False) <br>\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['null_total', 'null_percent_r']) <br>\n",
    "missing_data.head(5) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fit model\n",
    "y = train_df.Survived  <br>\n",
    "X_values = (['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']) <br>\n",
    "x = train_df[x_values] <br>\n",
    "train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=1) <br>\n",
    "rf_model.fit(train_x,train_y) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### map less common names to more common ones\n",
    "title_dict={'Capt':'Mr', 'Col':'Mr', 'Don':'Mr', 'Jonkheer':'Mr',   \n",
    "            'Lady':'Mrs', 'Major':'Mr', 'Mlle':'Miss', 'Mme':'Mrs',   \n",
    "            'Ms':'Miss', 'sir':'Mr', 'th':'Miss', 'Dona':'Mrs'}   \n",
    "train_df[\"Title\"] = train_df[\"Title\"].map(title_dict)  \n",
    "test_df[\"Title\"] = test_df[\"Title\"].map(title_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're gonna make a dictionary to make our matching (or .map()) easier  \n",
    "title_dict={'Capt':'Mr', 'Col':'Mr', 'Don':'Mr', 'Jonkheer':'Mr', 'Lady':'Mrs', 'Major':'Mr',   \n",
    "            'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss', 'sir':'Mr', 'th':'Miss', 'Dona':'Mrs'}  \n",
    "\n",
    "for variable in data:  \n",
    "    #map less frequent titles to more frequent ones  \n",
    "    variable['Title'] = variable['Title'].map(title_dict).fillna(0)  \n",
    "    #drop 'Name' we wont be using it anymore  \n",
    "    variable.drop('Name', axis=1, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Rule Algorithm Def\n",
    "class OneR(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ideal_variable = None\n",
    "        self.best_rule = None\n",
    "        self.max_accuracy = 0\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        response = list()\n",
    "        result = dict()\n",
    "        \n",
    "        dfx = pd.DataFrame(X)\n",
    "        \n",
    "        for i in dfx:\n",
    "            result[str(i)] = dict()\n",
    "            options_values = set(dfx[i])\n",
    "            join_data = pd.DataFrame({\"variable\":dfx[i], \"label\":y})\n",
    "            cross_table = pd.crosstab(join_data.variable, join_data.label)\n",
    "            summary = cross_table.idxmax(axis=1)\n",
    "            result[str(i)] = dict(summary)\n",
    "            \n",
    "            counts = 0\n",
    "            \n",
    "            for idx, row in join_data.iterrows():\n",
    "                if row['label'] == result[str(i)][row['variable']]:\n",
    "                    counts += 1\n",
    "\n",
    "            accuracy = (counts/len(y))\n",
    "            \n",
    "            if accuracy > self.max_accuracy:\n",
    "                self.max_accuracy = accuracy\n",
    "                self.ideal_variable = i\n",
    "                self.best_rule = result[str(i)]\n",
    "\n",
    "            result_feature = {\"variable\": str(i), \"accuracy\":accuracy, \"rules\": result[str(i)] }  \n",
    "            response.append(result_feature)\n",
    "            \n",
    "        return response\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X[self.ideal_variable].map(lambda x: self.best_rule[x])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self.ideal_variable != None:\n",
    "            txt = \"Best predictor is: \" + str(self.ideal_variable)\n",
    "        else:\n",
    "            txt = \"No predictor beats random sampling\"\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = ['slope_of_peak_exercise_st_segment',\n",
    "             'thal',\n",
    "             'resting_blood_pressure',\n",
    "             'chest_pain_type',\n",
    "             'num_major_vessels',\n",
    "             'fasting_blood_sugar_gt_120_mg_per_dl',\n",
    "             'resting_ekg_results',\n",
    "             'serum_cholesterol_mg_per_dl',\n",
    "             'oldpeak_eq_st_depression',\n",
    "             'sex',\n",
    "             'age',\n",
    "             'max_heart_rate_achieved',\n",
    "             'exercise_induced_angina',\n",
    "             'heart_rate/blood_pressure',\n",
    "             'cholesterol/blood_pressure',\n",
    "             'blood_pressure/age',\n",
    "             'cholesterol/age',\n",
    "             'heart_rate/age']\n",
    "X = train_values[X_columns]\n",
    "y = train_labels.heart_disease_present\n",
    "X_test = train_values[X_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onerule = OneR()\n",
    "onerule_fit = onerule.fit(X,y)\n",
    "\n",
    "#make One Rule output more presentable\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.DataFrame(onerule_fit).sort_values(by=['accuracy'], ascending=False).round(3).set_index('accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
